import os
import json
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI

load_dotenv()

CORPUS_PATH = "outputs/corpus.jsonl"
PROFILE_PATH = "outputs/user_profile.md"
PROFILE_STATE = "state/profile_state.json"

def _load_state():
    if not os.path.exists(PROFILE_STATE):
        return {"last_line": 0}
    with open(PROFILE_STATE, "r", encoding="utf-8") as f:
        return json.load(f)

def _save_state(state):
    with open(PROFILE_STATE, "w", encoding="utf-8") as f:
        json.dump(state, f, ensure_ascii=False, indent=2)

def _read_new_chunks(max_items=40):
    if not os.path.exists(CORPUS_PATH):
        return [], 0

    state = _load_state()
    last_line = int(state.get("last_line", 0))

    with open(CORPUS_PATH, "r", encoding="utf-8") as f:
        lines = f.readlines()

    new_lines = lines[last_line:]
    state["last_line"] = len(lines)
    _save_state(state)

    chunks = []
    for ln in new_lines:
        try:
            obj = json.loads(ln)
            chunks.append(obj)
        except:
            pass

    # æŒ‰æƒé‡æ’åºï¼Œå–æœ€æœ‰ä»·å€¼çš„éƒ¨åˆ†ï¼ˆçœ tokenï¼‰
    chunks.sort(key=lambda x: float(x.get("weight", 0.0)), reverse=True)
    return chunks[:max_items], len(new_lines)

def update_user_profile():
    if not os.getenv("GOOGLE_API_KEY"):
        print("âŒ ç¼ºå°‘ GOOGLE_API_KEYï¼Œæ— æ³•æ›´æ–°ç”»åƒ")
        return False

    chunks, raw_new_line_count = _read_new_chunks()
    if not chunks:
        print("ğŸ’¤ æ²¡æœ‰æ–°å¢ chunkï¼Œè·³è¿‡ç”»åƒæ›´æ–°ã€‚")
        return False

    old_profile = ""
    if os.path.exists(PROFILE_PATH):
        with open(PROFILE_PATH, "r", encoding="utf-8") as f:
            old_profile = f.read().strip()

    # å‹ç¼© evidence
    evidence = []
    for c in chunks:
        text = (c.get("text") or "").strip().replace("\n", " ")
        text = text[:500]
        evidence.append(
            f"- source={c.get('source')} weight={c.get('weight')} file={c.get('file_path')} created_at={c.get('created_at')}\n"
            f"  text={text}"
        )
    evidence_block = "\n".join(evidence)

    llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0.2)

    system = (
        "ä½ æ˜¯â€œç”¨æˆ·ç”»åƒæ›´æ–°å™¨â€ã€‚ä½ çš„ä»»åŠ¡ï¼šæ ¹æ®æ–°å¢è¯æ®ï¼Œæ›´æ–° user_profile.mdã€‚\n"
        "è§„åˆ™ï¼š\n"
        "1) è¾“å‡ºå¿…é¡»æ˜¯ Markdownï¼ˆä¸æ˜¯ JSONï¼‰ã€‚\n"
        "2) å°½é‡ä¿æŒç¨³å®šï¼Œåªåšå¢é‡æ›´æ–°ï¼Œä¸è¦å› ä¸ºå°‘é‡è¯æ®æ¨ç¿»æ—§ç»“è®ºã€‚\n"
        "3) ä»»ä½•æ–°å¢ç»“è®ºéƒ½è¦åœ¨â€œè¯æ®æ—¥å¿—â€é‡Œå†™æ˜æ¥æºï¼ˆsource/file/created_atï¼‰ã€‚\n"
        "4) æ–‡é£ï¼šç®€æ´ã€åƒå¤‡å¿˜å½•ã€‚\n"
        "è¯·ä½¿ç”¨å›ºå®šç»“æ„ï¼š\n"
        "# æ ¸å¿ƒæ€§æ ¼ä¸åå¥½\n"
        "# å†³ç­–ä¸å­¦ä¹ é£æ ¼\n"
        "# äº¤æ˜“é£æ ¼ä¸é£é™©åå¥½\n"
        "# å¸¸è§ç›²ç‚¹ä¸çº åæé†’\n"
        "# è¿‘æœŸå…³æ³¨ä¸å‡è®¾ï¼ˆå¯å˜åŒ–ï¼‰\n"
        "# è¯æ®æ—¥å¿—ï¼ˆè‡ªåŠ¨è¿½åŠ ï¼‰\n"
    )

    user = (
        f"ã€æ—§ç”»åƒã€‘\n{old_profile if old_profile else '(ç©º)'}\n\n"
        f"ã€æ–°å¢è¯æ®ï¼ˆæœ¬æ¬¡æ–°å¢ {raw_new_line_count} è¡Œ corpusï¼‰ã€‘\n{evidence_block}\n\n"
        "è¯·è¾“å‡ºæ›´æ–°åçš„å®Œæ•´ user_profile.md å†…å®¹ã€‚"
    )

    resp = llm.invoke([("system", system), ("human", user)])
    new_profile = (resp.content or "").strip()

    if not new_profile:
        print("âŒ æ¨¡å‹è¾“å‡ºä¸ºç©ºï¼Œè·³è¿‡å†™å…¥ã€‚")
        return False

    with open(PROFILE_PATH, "w", encoding="utf-8") as f:
        f.write(new_profile + "\n")

    print(f"âœ… user_profile.md å·²æ›´æ–°ï¼ˆå¸æ”¶ {len(chunks)} æ¡é«˜æƒé‡è¯æ®ï¼‰")
    return True

if __name__ == "__main__":
    update_user_profile()
