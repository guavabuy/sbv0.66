import os
import json
import requests
import datetime
from pathlib import Path
from dotenv import load_dotenv

# é¡¹ç›®æ ¹ç›®å½•ï¼ˆconnectors/ çš„ä¸Šä¸€çº§ï¼‰
_BASE = Path(__file__).resolve().parents[1]
try:
    load_dotenv(dotenv_path=_BASE / ".env")
except Exception:
    # åœ¨æŸäº›ç¯å¢ƒï¼ˆæƒé™/æ—  .envï¼‰ä¸‹å…è®¸å¯¼å…¥ï¼›çœŸå®è¿è¡Œæ—¶å¯ä¾èµ–ç¯å¢ƒå˜é‡
    pass
NOTION_KEY = os.getenv("NOTION_API_KEY")
DATABASE_ID = os.getenv("NOTION_DATABASE_ID")

# âœ… é¿å…å’Œ ingest çš„ sync_state.json å†²çª
STATE_FILE = str(_BASE / "state" / "notion_state.json")

headers = {
    "Authorization": f"Bearer {NOTION_KEY}",
    "Content-Type": "application/json",
    "Notion-Version": "2022-06-28"
}

def _parse_iso(ts: str) -> datetime.datetime:
    # Notion ç»å¸¸æ˜¯ ...Z
    if ts.endswith("Z"):
        ts = ts.replace("Z", "+00:00")
    return datetime.datetime.fromisoformat(ts)

def _safe_filename(s: str) -> str:
    return "".join(c if c.isalnum() or c in "._-+" else "_" for c in s)

def fetch_page_content(page_id: str) -> str:
    block_url = f"https://api.notion.com/v1/blocks/{page_id}/children"
    try:
        response = requests.get(block_url, headers=headers, timeout=20)
        if response.status_code != 200:
            return "[API é™åˆ¶æ— æ³•è¯»å–å†…å®¹]"

        blocks = response.json().get("results", [])
        content_text = ""

        for block in blocks:
            b_type = block.get("type")
            if b_type == "paragraph":
                rich_text = block.get("paragraph", {}).get("rich_text", [])
                for rt in rich_text:
                    content_text += rt.get("plain_text", "")
                content_text += "\n"
            elif b_type and "heading" in b_type:
                rich_text = block.get(b_type, {}).get("rich_text", [])
                heading = "".join(rt.get("plain_text", "") for rt in rich_text)
                if heading.strip():
                    content_text += f"\nã€{heading.strip()}ã€‘\n"

        return content_text.strip() if content_text.strip() else "[è¯¥ç¬”è®°æ²¡æœ‰æ–‡æœ¬å†…å®¹]"
    except Exception as e:
        return f"[è¯»å–é”™è¯¯: {e}]"

def fetch_updates() -> int:
    print(">>> ğŸ”„ å¼€å§‹æ™ºèƒ½åŒæ­¥ Notion...")
    if not NOTION_KEY or not DATABASE_ID:
        print("âš ï¸ [Notion] ç¼ºå°‘ NOTION_API_KEY æˆ– NOTION_DATABASE_IDï¼Œè·³è¿‡åŒæ­¥")
        return 0

    last_synced_time = ""
    if os.path.exists(STATE_FILE):
        with open(STATE_FILE, "r", encoding="utf-8") as f:
            state = json.load(f)
            last_synced_time = state.get("last_synced_time", "")
            print(f"ğŸ•’ ä¸Šæ¬¡åŒæ­¥æ—¶é—´: {last_synced_time}")

    if not last_synced_time:
        # åˆæ¬¡è¿è¡Œï¼šå…¨é‡åŒæ­¥ï¼ˆæŠ“å–å†å²æ‰€æœ‰æ­£æ–‡ï¼‰
        # ç”¨ 1970-01-01 ä½œä¸ºâ€œæœ€æ—©æ—¶é—´â€ï¼Œé¿å… Notion å¯¹éå¸¸æ—©çš„å¹´ä»½å…¼å®¹æ€§é—®é¢˜
        print("ğŸ†• åˆæ¬¡è¿è¡Œï¼šå°†è¿›è¡Œ Notion å…¨é‡åŒæ­¥ï¼ˆæŠ“å–å†å²æ‰€æœ‰æ­£æ–‡ï¼‰...")
        last_synced_dt = datetime.datetime(1970, 1, 1, tzinfo=datetime.timezone.utc)
    else:
        last_synced_dt = _parse_iso(last_synced_time)

    query_url = f"https://api.notion.com/v1/databases/{DATABASE_ID}/query"
    out_dir = str(_BASE / "data" / "raw" / "notion")
    os.makedirs(out_dir, exist_ok=True)

    # Notion æ•°æ®åº“ query æœ‰åˆ†é¡µï¼ˆæœ€å¤š 100/é¡µï¼‰
    start_cursor = None
    total_candidates = 0
    new_count = 0
    newest_dt = last_synced_dt

    while True:
        payload = {
            "page_size": 100,
            "filter": {
                "timestamp": "last_edited_time",
                "last_edited_time": {"on_or_after": last_synced_dt.isoformat()},
            },
            # ç¨³å®šæ’åºï¼šä»æ—§åˆ°æ–°ï¼Œæ–¹ä¾¿è§‚å¯Ÿå…¨é‡åŒæ­¥è¿›åº¦
            "sorts": [{"timestamp": "last_edited_time", "direction": "ascending"}],
        }
        if start_cursor:
            payload["start_cursor"] = start_cursor

        response = requests.post(query_url, json=payload, headers=headers, timeout=30)
        if response.status_code != 200:
            print(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {response.text}")
            return 0

        data = response.json()
        results = data.get("results", [])
        has_more = bool(data.get("has_more"))
        start_cursor = data.get("next_cursor")

        if not results and total_candidates == 0:
            print("âœ… æ²¡æœ‰å‘ç°æ–°å†…å®¹ã€‚")
            current_time_iso = datetime.datetime.now(datetime.timezone.utc).isoformat()
            with open(STATE_FILE, "w", encoding="utf-8") as f:
                json.dump({"last_synced_time": current_time_iso}, f, ensure_ascii=False, indent=2)
            return 0

        total_candidates += len(results)
        if results:
            print(f"ğŸ“¦ æœ¬é¡µå‘ç° {len(results)} æ¡å€™é€‰ç¬”è®°ï¼ˆç´¯è®¡ {total_candidates}ï¼‰ï¼Œæ­£åœ¨æŠ“å–æ­£æ–‡...")

        for page in results:
            page_id = page["id"]
            last_edit = page["last_edited_time"]
            last_edit_dt = _parse_iso(last_edit)

            # äºŒæ¬¡ä¿é™©ï¼šNotion è¿‡æ»¤æ˜¯ on_or_afterï¼ˆåŒ…å«æ–­ç‚¹æ—¶åˆ»æœ¬èº«ï¼‰
            if last_edit_dt <= last_synced_dt:
                continue

            props = page.get("properties", {})
            title = "æ— æ ‡é¢˜"
            for _, val in props.items():
                if val.get("id") == "title" and val.get("title"):
                    title = val["title"][0]["plain_text"]
                    break

            print(f"   -> æ­£åœ¨è¯»å–: {title} ...")
            content = fetch_page_content(page_id)

            # âœ… æ¯ç¯‡ç¬”è®°ä¸€ä¸ªæ–‡ä»¶ï¼šé¿å… ingest åå¤æŠŠæ—§å†…å®¹åƒè¿›å»
            safe_ts = _safe_filename(last_edit_dt.isoformat())
            safe_title = _safe_filename(title)[:80]
            file_path = os.path.join(out_dir, f"{safe_ts}_{page_id}_{safe_title}.md")

            doc = (
                f"# {title}\n"
                f"- source: notion\n"
                f"- notion_page_id: {page_id}\n"
                f"- last_edited_time: {last_edit}\n\n"
                f"{content}\n"
            )

            with open(file_path, "w", encoding="utf-8") as f:
                f.write(doc)

            new_count += 1
            if last_edit_dt > newest_dt:
                newest_dt = last_edit_dt

        if not has_more:
            break

    # åªè¦æœ‰æ–°å†…å®¹ï¼Œå°±æŠŠæ–­ç‚¹æ¨è¿›åˆ°æœ€æ–°ä¸€ç¯‡çš„æ—¶é—´
    if new_count > 0:
        with open(STATE_FILE, "w", encoding="utf-8") as f:
            json.dump({"last_synced_time": newest_dt.isoformat()}, f, ensure_ascii=False, indent=2)
        print(f"ğŸ‰ æˆåŠŸåŒæ­¥ {new_count} æ¡ç¬”è®°æ­£æ–‡ï¼")
    else:
        print("âœ… ç»“æœéƒ½æ˜¯æ—§çš„ï¼Œæ— éœ€æ›´æ–°ã€‚")

    return new_count

if __name__ == "__main__":
    fetch_updates()