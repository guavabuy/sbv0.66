import os
import json
import time
import random
import sys
import re
from pathlib import Path
from datetime import datetime, timezone
from dotenv import load_dotenv

_ROOT = Path(__file__).resolve().parents[1]
if str(_ROOT) not in sys.path:
    sys.path.insert(0, str(_ROOT))

CORPUS_PATH = "data/corpus.jsonl"
PROFILE_PATH = "data/user_profile.md"
PROFILE_STATE = "state/profile_state.json"

def env_bool(name: str, default: str = "0") -> bool:
    return (os.getenv(name, default).strip().lower() in ("1", "true", "yes", "y", "on"))


def env_int(name: str, default: str = "0") -> int:
    try:
        return int(os.getenv(name, default) or default)
    except Exception:
        return int(default)

def _parse_dt(s: str):
    if not s:
        return None
    try:
        return datetime.fromisoformat(s.replace("Z", "+00:00"))
    except Exception:
        return None


def _infer_dt_from_notion_filename(file_path: str):
    m = re.search(
        r"/notion/([0-9]{4}-[0-9]{2}-[0-9]{2}T[0-9]{2}_[0-9]{2}_[0-9]{2}[^_/]*)_",
        (file_path or "").replace("\\", "/"),
    )
    if not m:
        return None
    ts = m.group(1).replace("_", ":")
    if "+" not in ts and "Z" not in ts:
        ts = ts + "+00:00"
    return _parse_dt(ts)

def _is_overload_error(e: Exception) -> bool:
    msg = str(e)
    return ("503" in msg) or ("overloaded" in msg.lower()) or ("UNAVAILABLE" in msg)

def _retry(callable_fn, retries=6, base_delay=2.0, max_delay=30.0):
    """
    åªå¯¹ 503/overloaded åšé‡è¯•ï¼›å…¶ä»–é”™è¯¯ç›´æ¥æŠ›å‡ºã€‚
    """
    for i in range(retries):
        try:
            return callable_fn()
        except Exception as e:
            if not _is_overload_error(e):
                raise
            sleep_s = min(max_delay, base_delay * (2 ** i) + random.random())
            print(f"âš ï¸ [LLM] 503/overloadedï¼Œç¬¬ {i+1}/{retries} æ¬¡é‡è¯•ï¼Œ{sleep_s:.1f}s åå†è¯•â€¦")
            time.sleep(sleep_s)
    raise RuntimeError("LLM 503/overloadedï¼šå¤šæ¬¡é‡è¯•ä»å¤±è´¥")

def _load_state():
    if not os.path.exists(PROFILE_STATE):
        return {"last_line": 0}
    with open(PROFILE_STATE, "r", encoding="utf-8") as f:
        return json.load(f)

def _save_state(state):
    with open(PROFILE_STATE, "w", encoding="utf-8") as f:
        json.dump(state, f, ensure_ascii=False, indent=2)

def _read_new_chunks(max_items=40):
    # 1. å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œç›´æ¥è¿”å›ç©ºåˆ—è¡¨å’Œ0
    if not os.path.exists(CORPUS_PATH):
        # å…¼å®¹æ—§ç›®å½•
        if os.path.exists("outputs/corpus.jsonl"):
            return _read_new_chunks_from_path("outputs/corpus.jsonl", max_items=max_items)
        return [], 0

    # 2. è¯»å–æ—§çš„çŠ¶æ€
    state = _load_state()
    last_line = int(state.get("last_line", 0))

    # 3. è¯»å–æ–‡ä»¶æ‰€æœ‰è¡Œ
    with open(CORPUS_PATH, "r", encoding="utf-8") as f:
        lines = f.readlines()

    # ã€å…³é”®ä¿®å¤ã€‘æ— è®ºæ˜¯å¦æœ‰æ–°å†…å®¹ï¼Œå…ˆç¡®å®šç°åœ¨çš„æ€»è¡Œæ•°
    new_last_line = len(lines)

    # 4. æˆªå–æ–°å¢åŠ çš„è¡Œ
    new_lines = lines[last_line:]

    chunks = []
    for ln in new_lines:
        try:
            obj = json.loads(ln)
            chunks.append(obj)
        except:
            pass

    # ã€å…³é”®ä¿®å¤ã€‘å¿…é¡»æŠŠ chunks å’Œ new_last_line éƒ½è¿”å›å‡ºå»
    return chunks, new_last_line


def _read_new_chunks_from_path(path: str, max_items=40):
    """
    å…¼å®¹æ—§ outputs/ è·¯å¾„è¯»å–å¢é‡ã€‚
    """
    if not os.path.exists(path):
        return [], 0
    state = _load_state()
    last_line = int(state.get("last_line", 0))
    with open(path, "r", encoding="utf-8") as f:
        lines = f.readlines()
    new_last_line = len(lines)
    new_lines = lines[last_line:]
    chunks = []
    for ln in new_lines:
        try:
            obj = json.loads(ln)
        except Exception:
            continue
        t = (obj.get("text") or "").strip()
        if not t:
            continue
        chunks.append(t)
        if len(chunks) >= int(max_items or 40):
            break
    return chunks, new_last_line

def update_user_profile():
    # å»¶è¿ŸåŠ è½½ï¼šé¿å…åœ¨æŸäº›ç¯å¢ƒ import è„šæœ¬æ—¶å°±è§¦å‘å¤§ä¾èµ–åŠ è½½/æƒé™é—®é¢˜
    load_dotenv()
    from langchain_google_genai import ChatGoogleGenerativeAI

    if not os.getenv("GOOGLE_API_KEY"):
        print("âŒ ç¼ºå°‘ GOOGLE_API_KEYï¼Œæ— æ³•æ›´æ–°ç”»åƒ")
        return False
        
    state = _load_state()
    chunks, new_last_line = _read_new_chunks()
    old_last_line = int(state.get("last_line", 0))
    raw_new_line_count = new_last_line - old_last_line

    if not chunks:
        print("ğŸ’¤ æ²¡æœ‰æ–°å¢ chunkï¼Œè·³è¿‡ç”»åƒæ›´æ–°ã€‚")
        return False

    # ç²¾ç®€ç‰ˆï¼šä¸åšæƒé‡/è¡°å‡ rerankï¼Œåªåšâ€œæœ€å¤šå–å‰ N æ¡æ–°å¢è¯æ®â€é¿å…æç¤ºè¯è¿‡é•¿
    top_n = env_int("SB_PROFILE_EVIDENCE_TOP_N", "40")
    chunks = chunks[: int(top_n)]

    old_profile = ""
    if os.path.exists(PROFILE_PATH):
        with open(PROFILE_PATH, "r", encoding="utf-8") as f:
            old_profile = f.read().strip()
            state = _load_state()
            state["last_line"] = new_last_line
            _save_state(state)


    # å‹ç¼© evidence
    evidence = []
    for c in chunks:
        text = (c.get("text") or "").strip().replace("\n", " ")
        text = text[:500]
        evidence.append(
            f"- source={c.get('source')} weight={c.get('weight')} file={c.get('file_path')} created_at={c.get('created_at')}\n"
            f"  text={text}"
        )
    evidence_block = "\n".join(evidence)

    llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0.2)

    system = (
        "ä½ æ˜¯â€œç”¨æˆ·ç”»åƒæ›´æ–°å™¨â€ã€‚ä½ çš„ä»»åŠ¡ï¼šæ ¹æ®æ–°å¢è¯æ®ï¼Œæ›´æ–° user_profile.mdã€‚\n"
        "è§„åˆ™ï¼š\n"
        "1) è¾“å‡ºå¿…é¡»æ˜¯ Markdownï¼ˆä¸æ˜¯ JSONï¼‰ã€‚\n"
        "2) å°½é‡ä¿æŒç¨³å®šï¼Œåªåšå¢é‡æ›´æ–°ï¼Œä¸è¦å› ä¸ºå°‘é‡è¯æ®æ¨ç¿»æ—§ç»“è®ºã€‚\n"
        "3) ä»»ä½•æ–°å¢ç»“è®ºéƒ½è¦åœ¨â€œè¯æ®æ—¥å¿—â€é‡Œå†™æ˜æ¥æºï¼ˆsource/file/created_atï¼‰ã€‚\n"
        "4) æ–‡é£ï¼šç®€æ´ã€åƒå¤‡å¿˜å½•ã€‚\n"
        "è¯·ä½¿ç”¨å›ºå®šç»“æ„ï¼š\n"
        "# æ ¸å¿ƒæ€§æ ¼ä¸åå¥½\n"
        "# å†³ç­–ä¸å­¦ä¹ é£æ ¼\n"
        "# äº¤æ˜“é£æ ¼ä¸é£é™©åå¥½\n"
        "# å¸¸è§ç›²ç‚¹ä¸çº åæé†’\n"
        "# è¿‘æœŸå…³æ³¨ä¸å‡è®¾ï¼ˆå¯å˜åŒ–ï¼‰\n"
        "# è¯æ®æ—¥å¿—ï¼ˆè‡ªåŠ¨è¿½åŠ ï¼‰\n"
    )

    user = (
        f"ã€æ—§ç”»åƒã€‘\n{old_profile if old_profile else '(ç©º)'}\n\n"
        f"ã€æ–°å¢è¯æ®ï¼ˆæœ¬æ¬¡æ–°å¢ {raw_new_line_count} è¡Œ corpusï¼‰ã€‘\n{evidence_block}\n\n"
        "è¯·è¾“å‡ºæ›´æ–°åçš„å®Œæ•´ user_profile.md å†…å®¹ã€‚"
    )
    prompt = f"{system}\n\n{user}"
    resp = _retry(lambda: llm.invoke(prompt))
    new_profile = (resp.content or "").strip()

    if not new_profile:
        print("âŒ æ¨¡å‹è¾“å‡ºä¸ºç©ºï¼Œè·³è¿‡å†™å…¥ã€‚")
        return False

    # Card 6ï¼šç¡®ä¿ data/ ç›®å½•å­˜åœ¨
    try:
        os.makedirs(os.path.dirname(PROFILE_PATH), exist_ok=True)
    except Exception:
        pass

    with open(PROFILE_PATH, "w", encoding="utf-8") as f:
        f.write(new_profile + "\n")

    print(f"âœ… user_profile.md å·²æ›´æ–°ï¼ˆå¸æ”¶ {len(chunks)} æ¡é«˜æƒé‡è¯æ®ï¼‰")
    return True

if __name__ == "__main__":
    update_user_profile()


